הסבר על המחלקות והתיקיות המרכיבות את הפרויקט:
תיקיות:
•	buggedFiles - תיקייה שמכילה טבלה ובה יש לשים את רשימת הקבצים התקולים עבור כל גרסה.
•	jcov_hive – תיקייה בה שמורים כל הקבצים שנאספו בשלב הראשון ע"י הרצת jcov hive (קבצי xml ו-html).
•	temporaryFiles – תיקייה בה נשמרים כל הקבצים הזמניים הנדרשים עבור הרצת המודל (טבלאות csv):
o	הקבצים שנוצרו לאחר שלב ה-parsing: parsing_table+version_name
o	הקבצים שנוצרו לאחר שלב ה-features extraction  (עדיין ללא ה-class): features_table+version_name
o	הקבצים המעובדים עבור הרצת המודל ובהם כל הנתונים על קבוצת האימון וקבוצת המבחן – data_train, data_test


מחלקות:
•	xml_parse.py – מחלקה זו מקבלת קובץ xml המכיל את הנתונים מהרצת חבילות הבדיקה על הקבצים ומייצרת טבלת csv שבה נשמרים כל הנתונים שישמשו לשלב ה-feature extraction. המחלקה כוללת 2 פונקציות:
1.	def parsing_xml(version_name, perform_new_parse=True):
פונקציה זו אחראית על סידור הנתונים בצורה קריאה ונוחה למשתמש, לאחר עיבוד כל הנתונים, הם נשמרים בטבלה בשם: 'parsing_table_' + version_name + '.csv' בתוך תיקיית - Temporary Files.
הפונקציה מקבלת שני פרמטרים:
 1) version_name – string שמתאר מהי הגרסה הנוכחית שיש לפרסר.
 2) perform_new_parse – משתנה Boolean, True – במידה ורוצים לבצע את תהליך הפירסור מההתחלה, False- במידה ורוצים לחסוך את ביצוע תהליך הפירסור מההתחלה ורוצים להשתמש בטבלה שנוצרה בריצה הקודמת.

2.	def add_to_table(class_path, method_name, , …., is_goto, table) :
פונקציה המקבלת את כל הנתונים שנאספו עבור בלוק מסויים בתהליך הפירסור ושומרת אותם בצורה מסודרת בטבלה. עבור כל בלוק מתבצעת קריאה אחת לפונקציה זו, ונשמרת שורה אחת בלבד בטבלה. (פירוט על הטבלה בנספח א')

•	feature_extraction.py – מחלקה זו אחראית על שלבים 3 ו-4, היא אחראית על עיבוד המידע לאחר שלב הפירסור, ויצירת פיצ'רים לפי בלוקים ופונקציות עבור הקבצים השונים.
מחלקה זו כוללת שלוש פונקציות:
1.	def create_block_features(version_name, data, perform_new_feature_extraction): פונקציה זו מכילה את רוב הקוד עבור יצירת הפיצ'רים, ומכילה שני חלקים (region)
a.	Collecting data - סידור כל הנתונים בצורה נוחה לחישוב וניתוח
b.	Building features – בניית הפיצ'רים עבור כל קובץ
 לאחר יצירת הפיצ'רים הם נשמרים בטבלה בשם: ' features_table_' + version_name + '.csv' בתוך תיקיית - Temporary Files.
הפונקציה מקבלת שלושה פרמטרים:
1) version_name – string שמתאר מהי הגרסה שיוצרים עבורה את הפיצ'רים.
2) data – במידה ובשלב הקודם בוצע תהליך הפירסור במלואו (parsing=yes), בסוף התהליך נוצר אובייקט מסוג data Frame אשר ניתן לעבוד לפיו.
3) perform_new_feature_extraction – משתנה Boolean, True – במידה ורוצים לבצע את תהליך בניית הפיצ'רים מההתחלה, False- במידה ורוצים לחסוך את ביצוע תהליך זה מההתחלה ורוצים להשתמש בטבלה שנוצרה בריצה הקודמת.

2.	def create_inner_bl_hc_list(bl_hc_list, bl_type_list):  פונקציה שמחזירה רק את ה-hit count של בלוקים פנימיים  - inner block (ללא בלוקים שהם התחלה/סוף של פונקציה).
3.	def create_filtered_list(filt, source_list, factor_list): פונקציה אשר מסננת רשימה של hit count  לפי קריטריון מסויים (למשל רק hit count של בלוקים מסוג cond).

•	parse_results.py – מחלקה זו עוברת על כל הקבצים שנמצאו תקולים ובונה מילון שבו עבור כל גרסה רשימה עם כל הקבצים התקולים (בעלי סיומת מסוג .java) של אותה גרסה. במחלקה זו קיימת פונקציה אחת בשם - def get_bugged_files() אשר מחזירה את המילון שנבנה.

•	main.py  - המחלקה בה מריצים את המודל המלא: תחילה מעבדים את המידע שהתקבל ומכינים את קבצי האימון והמבחן להרצת המודל, לאחר כן מריצים את המודל לפי קבוצות הפיצ'רים שמתוארות בנספח ב' ושומרים את כלל התוצאות בקובץ: Model result.csv.
המחלקה מכילה את הפונקציות הבאות:
1.	def prepare_data(training,versions_array, bugged_paths, dic_versions):
הפונקציה אחראית על הכנת הנתונים, ומקבלת את הפרמטרים הבאים:
1)	training – במידה והוא שווה לTRUE הפונקציה מכינה את נתוני האימון, במידה והוא מקבל FALSE הפונקציה מכינה את נתוני המבחן.
2)	version_array – רשימת הגרסאות שעבורן נכין את הנתונים.
3)	bugged_paths – רשימת כל הקבצים התקולים לפי גרסאות.
4)	dic_version – מילון שממפה בין השמות של הגרסאות שהתקבלו מקבצי ה- xml והשמות של הגרסאות שהתקבלו עבור הקבצים התקולים.

2.	def build_model(x_train, y_train, x_test, y_test): פונקציה שאחראית על בניית מודל הלמידה  מסוג Random Forest, אימון המודל לפי קבצי האימון (x_train, y_train), בדיקת המודל ע"י קבצי המבחן (x_test, y_test) והדפסת התוצאות שהתקבלו לפי המדדים: Accuracy, AUC area, Precision, Recall.

-	train_files – רשימה ובה כל הגרסאות שיכילו את קבוצת האימון, לדוגמא:
o	train_files = ['1_7_jcov', '1_7_rc2_jcov', '1_8_jcov']
-	test_files – רשימה ובה כל הגרסאות שיכילו את קבוצת המבחן, לדוגמא:
o	test_files = ['1_8_rc2_jcov']


תיאור הרצת המודל:
בשביל להריץ את המודל צריך להזין ב-Run/Decug Configuration את הפרמטרים הבאים:
1.	parsing –
a.	במידה ורוצים לבצע את שלב ה-parsing  מההתחלה יש להזין: parsing=yes .
b.	במידה ורוצים להשתמש בטבלאות המוכנות ) 'parsing_table_' + version_name + '.csv' ( שנוצרו לאחר שלב זה יש להזין: parsing=no.
2.	feature_extraction –
a.	במידה ורוצים לבצע את שלב יצירת הפיצ'רים מההתחלה יש להזין: feature_extraction=yes .
b.	במידה ורוצים להשתמש בטבלאות המוכנות ) ' feature _table_' + version_name + '.csv' ( שנוצרו לאחר שלב זה יש להזין: feature_extraction=no .
3.	process_data –
a.	במידה ולא רוצים להשתמש במידע המעובד (train_data.csv, test_data.csv) ורוצים לבצע את התהליך המלא או את חלקו מההתחלה (כלומר לעבד את הנתונים)  יש להזין: process_data=yes .
b.	במידה ורוצים להשתמש בטבלאות המוכנות (train_data.csv, test_data.csv)  שנוצרו בסוף תהליך עיבוד הנתונים יש להזין : process_data=no.

לאחר מכן ניתן ללחוץ על Run main ויבנו המודלים הבאים  (לפי הסדר הנ"ל):
1.	בניית המודל לפי כל הפיצ'רים שנוצרו (Group name – all features)
2.	בניית המודל לפי הפיצ'רים שמתייחסים לבלוקים (Group name – block features)
3.	בניית המודל לפי הפיצ'רים שמתייחסים לפונקציות Group name – function features))
4.	בניית המודל לפי קבוצות הפיצ'רים כאשר כל פעם:
a.	בונים את המודל רק לפי אותה קבוצה (Group name – with ____ )
b.	בונים את המודל ללא אותה קבוצה (Group name – without ___ )
